# MLT-Papers
Awesome papers in machine learning theory.

## Contents
- [Books](#books)
- [Learning Theory](#learning-theory)
- [Kernel Methods and Regularization](#kernel-regularization)
- [Theory of Neural Networks](#nn-theory)


<a name="books" />

## Books

1. **The Modern Mathematics of Deep Learning.**
    - arXiv 2021.
    - *Julius Berner, Philipp Grohs, Gitta Kutyniok, Philipp Petersen.*
    - [book](https://arxiv.org/pdf/2105.04026.pdf)
    

<a name="learning-theory" />

## Learning Theory

1. **Learnability and the Vapnik-Chervonenkis Dimension.**
    - Journal of the Association for Computing Machinery 1989.
    - *Anselm Blumer, Andrzej Ehrenfeucht, David Haussler, Manfred M. Warmuth.*
    - [paper](http://www2.denizyuret.com/ref/blumer/ft_gateway.cfm.pdf)
    
1. **Sample Compression, Learnability, and the Vapnik-Chervonenkis Dimension.**
    - Machine Learning 1995.
    - *Sally Floyd, Manfred Warmuth.*
    - [paper](https://link.springer.com/content/pdf/10.1023/A:1022660318680.pdf)

1. **Characterizations of Learnability for Classes of ${0, \dots, n}$-valued Functions.**
    - Journal of Computer and System Sciences 1995.
    - *Shai Ben-David, Nicolo Cesa-Bianchi, David Haussler, Philip M. Long.*
    - [paper](http://phillong.info/publications/chars.pdf)

1. **Scale-Sensitive Dimensions, Uniform Convergence, and Learnability.**
    - JACM 1997.
    - *Noga Alon, Shai Ben-David, Nicolo Cesa-Bianchi, David Haussler.*
    - [paper](http://cesa-bianchi.di.unimi.it/Pubblicazioni/jacm-97b.pdf)
    
1. **Regret Bounds for Prediction Problems.**
    - COLT 1999.
    - *Geoffrey J. Gordon.*
    - [paper](https://dl.acm.org/doi/pdf/10.1145/307400.307410)

1. **A Study About Algorithmic Stability and Their Relation to Generalization Performances.**
    - Technical Report 2000.
    - *Andre Elissee.*
    - [paper](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.33.4615&rep=rep1&type=pdf)

1. **Algorithmic Stability and Generalization Performance.**
    - NIPS 2001.
    - *Olivier Bousquet, Andre Elisseeff.*
    - [paper](https://papers.nips.cc/paper/1854-algorithmic-stability-and-generalization-performance.pdf)

1. **A Generalized Representer Theorem.**
    - COLT 2001.
    - *Bernhard Scholkopf, Ralf Herbrich, Alex J. Smola.*
    - [paper](https://www.cise.ufl.edu/class/cap6617fa15/Readings/SchHerSmo01.pdf)
    
1. **Concentration Inequalities and Empirical Processes Theory Applied to the Analysis of Learning Algorithms.**
    - Phd Thesis 2002.
    - *Olivier Bousquet.*
    - [paper](https://www.researchgate.net/publication/239060748_Concentration_inequalities_and_empirical_processes_theory_applied_to_the_analysis_of_learning_algorithms)
    
1. **Rademacher and Gaussian Complexities: Risk Bounds and Structural Results.**
    - JMLR 2002.
    - *Peter L. Bartlett, Shahar Mendelson.*
    - [paper](http://www.jmlr.org/papers/volume3/bartlett02a/bartlett02a.pdf)

1. **Stability and Generalization.**
    - JMLR 2002.
    - *Olivier Bousquet, Andre Elisseeff.*
    - [paper](http://www.jmlr.org/papers/volume2/bousquet02a/bousquet02a.pdf)
    
1. **Almost-Everywhere Algorithmic Stability and Generalization Error.**
    - UAI 2002.
    - *Samuel Kutin, Partha Niyogi.*
    - [paper](https://arxiv.org/pdf/1301.0579.pdf)
    
1. **PAC-Bayes & Margins.**
    - NIPS 2003.
    - *John Langford, John Shawe-Taylor.*
    - [paper](https://papers.nips.cc/paper/2317-pac-bayes-margins.pdf)
    
1. **Statistical Behavior and Consistency of Classification Methods based on Convex Risk Minimization.**
    - Annals of Statistics 2004.
    - *Tong Zhang.*
    - [paper](https://projecteuclid.org/download/pdf_1/euclid.aos/1079120130)
    
1. **Theory of Classification: A Survey of Some Recent Advances.**
    - ESAIM: Probability and Statistics 2005.
    - *Stephane Boucheron, Olivier Bousquet, Gabor Lugosi.*
    - [paper](https://www.esaim-ps.org/articles/ps/pdf/2005/01/ps0420.pdf)
    
1. **Learning Theory: Stability is Sufficient for Generalization and Necessary and Sufficient for Consistency of Empirical Risk Minimization.**
    - Advances in Computational Mathematics 2006.
    - *Sayan Mukherjee, Partha Niyogi, Tomaso Poggio, Ryan Rifkin.*
    - [paper](https://link.springer.com/content/pdf/10.1007/s10444-004-7634-z.pdf)
    
1. **Tutorial on Practical Prediction Theory for Classification.**
    - JMLR 2006.
    - *John Langford.*
    - [paper](http://www.jmlr.org/papers/volume6/langford05a/langford05a.pdf)
    
1. **Rademacher Complexity Bounds for Non-I.I.D. Processes.**
    - NIPS 2008.
    - *Mehryar Mohri, Afshin Rostamizadeh.*
    - [paper](https://papers.nips.cc/paper/3489-rademacher-complexity-bounds-for-non-iid-processes.pdf)
    
1. **On the Complexity of Linear Prediction: Risk Bounds, Margin Bounds, and Regularization.**
    - NIPS 2008.
    - *Sham M. Kakade, Karthik Sridharan, and Ambuj Tewari.*
    - [paper](https://www.cs.cornell.edu/~sridharan/rad-paper.pdf)
    
1. **Agnostic Online Learning.**
    - COLT 2009.
    - *Shai Ben-David, David Pal, Shai Shalev-Shwartz.*
    - [paper](https://www.cs.huji.ac.il/~shais/papers/BendavidPalShalevtech09.pdf)
    
1. **Learnability, Stability and Uniform Convergence.**
    - JMLR 2010.
    - *Shai Shalev-Shwartz, Ohad Shamir, Nathan Srebro, Karthik Sridharan.*
    - [paper](http://jmlr.csail.mit.edu/papers/volume11/shalev-shwartz10a/shalev-shwartz10a.pdf)
    
1. **Multiclass Learnability and the ERM Principle.**
    - COLT 2011.
    - *Amit Daniely, Sivan Sabato, Shai Ben-David, Shai Shalev-Shwartz.*
    - [paper](http://proceedings.mlr.press/v19/daniely11a/daniely11a.pdf)
    
1. **Algorithmic Stability and Hypothesis Complexity.**
    - ICML 2017.
    - *Tongliang Liu, Gábor Lugosi, Gergely Neu, Dacheng Tao.*
    - [paper](https://arxiv.org/pdf/1702.08712.pdf)
    
1. **Stability and Generalization of Learning Algorithms that Converge to Global Optima.**
    - ICML 2018.
    - *Zachary Charles, Dimitris Papailiopoulos.*
    - [paper](https://arxiv.org/pdf/1710.08402.pdf)
    
1. **Generalization Bounds for Uniformly Stable Algorithms.**
    - NIPS 2018.
    - *Vitaly Feldman, Jan Vondrak.*
    - [paper](https://arxiv.org/pdf/1812.09859.pdf)


<a name="kernel-regularization" />

## Kernel Methods and Regularization

1. **Think Globally, Fit Locally Under the Manifold Setup: Asymptotic Analysis of Locally Linear Embedding.**
    - Annals of Statistics 2018.
    - *Hau-Tieng Wu, Nan Wu.*
    - [paper](https://projecteuclid.org/download/pdfview_1/euclid.aos/1536631291)

1. **Convergence Analysis of Tikhonov Regularization for Non-Linear Statistical Inverse Learning Problems.**
    - arXiv 2019.
    - *Abhishake Rastogi, Gilles Blanchard, Peter Mathé.*
    - [paper](https://arxiv.org/pdf/1902.05404.pdf)
    
    
<a name="nn-theory" />
 
## Theory of Neural Networks

1. **Regularization Algorithms for Learning that are Equivalent to Multilayer Networks.**
    - Science 1990.
    - *T. Poggio, F. Girosi.*
    - [paper](http://cbcl.mit.edu/people/poggio/journals/poggio-girosi-science-1990.pdf)
    
1. **Strong Universal Consistency of Neural Network Classifiers.**
    - IEEE Transactions on Information Theory 1993.
    - *AndrAs Farag, GAbor Lugosi.*
    - [paper](https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=243433)
 
1. **For Valid Generalization, the Size of the Weights is More Important Than the Size of the Network.**
    - NIPS 1996.
    - *Peter L. Bartlett.*
    - [paper](https://papers.nips.cc/paper/1996/file/fb2fcd534b0ff3bbed73cc51df620323-Paper.pdf)
    
1. **Benefits of Depth in Neural Networks.**
    - COLT 2016.
    - *Matus Telgarsky.*
    - [paper](https://arxiv.org/pdf/1602.04485.pdf)

1. **Understanding Deep Learning Requires Rethinking Generalization.**
    - ICLR 2017.
    - *Chiyuan Zhang, Samy Bengio, Moritz Hardt, Benjamin Recht, Oriol Vinyals.*
    - [paper](https://arxiv.org/pdf/1611.03530.pdf)
    
1. **Convergence Analysis of Two-layer Neural Networks with ReLU Activation.**
    - arXiv 2017.
    - *Yuanzhi Li, Yang Yuan.*
    - [paper](https://arxiv.org/pdf/1705.09886.pdf)
    
1. **PAC-Bayesian Margin Bounds for Convolutional Neural Networks.**
    - arXiv 2018
    - *Konstantinos Pitas, Mike Davies, Pierre Vandergheynst.*
    - [paper](https://arxiv.org/pdf/1801.00171.pdf)
    - [code](https://github.com/konstantinos-p/PAC_Bayesian_Generalization)
    
1. **To Understand Deep Learning We Need to Understand Kernel Learning.**
    - ICML 2018.
    - *Mikhail Belkin, Siyuan Ma, Soumik Mandal.*
    - [paper](https://arxiv.org/pdf/1802.01396.pdf)
    
1. **The Vapnik–Chervonenkis Dimension of Graph and Recursive Neural Networks.**
    - ML 2018.
    - *Franco Scarselli, Ah Chung Tsoi, Markus Hagenbuchner.*
    - [paper](https://www.sciencedirect.com/science/article/pii/S0893608018302363)
    
1. **Explicitizing an Implicit Bias of the Frequency Principle in Two-layer Neural Networks.**
    - arXiv 2019.
    - *Yaoyu Zhang, Zhi-Qin John Xu, Tao Luo, Zheng Ma.*
    - [paper](https://arxiv.org/pdf/1905.10264.pdf)
    
1. **Learning and Generalization in Overparameterized Neural Networks, Going Beyond Two Layers.**
    - NIPS 2019.
    - *Zeyuan Allen-Zhu, Yuanzhi Li, Yingyu Liang.*
    - [paper](https://arxiv.org/pdf/1811.04918.pdf)
    
1. **Training Two-Layer ReLU Networks with Gradient Descent is Inconsistent.**
    - arXiv 2020.
    - *David Holzmuller, Ingo Steinwart.*
    - [paper](https://arxiv.org/pdf/2002.04861.pdf)
    
